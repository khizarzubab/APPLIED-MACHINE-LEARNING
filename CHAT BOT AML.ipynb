{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPBvW8gPBQB_",
        "outputId": "93178d48-ea87-40a5-922a-7f5511a95dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 38\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 115\n",
            "Max sequence length for inputs: 9\n",
            "Max sequence length for outputs: 40\n",
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0042 - loss: 4.7379 - val_accuracy: 0.4094 - val_loss: 4.5625\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709ms/step - accuracy: 0.6050 - loss: 4.4779 - val_accuracy: 0.4187 - val_loss: 4.2739\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.6175 - loss: 4.0526 - val_accuracy: 0.4187 - val_loss: 3.3374\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6125 - loss: 2.6021 - val_accuracy: 0.4094 - val_loss: 4.1070\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.6000 - loss: 2.3384 - val_accuracy: 0.4187 - val_loss: 3.2984\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6125 - loss: 2.0941 - val_accuracy: 0.4187 - val_loss: 3.4065\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.6117 - loss: 2.0598 - val_accuracy: 0.4187 - val_loss: 3.3063\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.6117 - loss: 2.0370 - val_accuracy: 0.4187 - val_loss: 3.3286\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.6117 - loss: 2.0182 - val_accuracy: 0.4187 - val_loss: 3.2687\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.6117 - loss: 2.0015 - val_accuracy: 0.4187 - val_loss: 3.2811\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.6117 - loss: 1.9860 - val_accuracy: 0.4187 - val_loss: 3.2189\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6125 - loss: 1.9717 - val_accuracy: 0.4187 - val_loss: 3.2540\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.6125 - loss: 1.9583 - val_accuracy: 0.4187 - val_loss: 3.1447\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.6125 - loss: 1.9475 - val_accuracy: 0.4187 - val_loss: 3.3134\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.6125 - loss: 1.9485 - val_accuracy: 0.4187 - val_loss: 2.9924\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.6133 - loss: 1.9942 - val_accuracy: 0.4187 - val_loss: 3.7178\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.6117 - loss: 2.1165 - val_accuracy: 0.4187 - val_loss: 2.9447\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6133 - loss: 1.9646 - val_accuracy: 0.4187 - val_loss: 3.3173\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6125 - loss: 1.9487 - val_accuracy: 0.4219 - val_loss: 2.9105\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.6142 - loss: 1.9139 - val_accuracy: 0.4187 - val_loss: 3.4191\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - accuracy: 0.6125 - loss: 1.9718 - val_accuracy: 0.4187 - val_loss: 2.9630\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - accuracy: 0.6125 - loss: 1.9305 - val_accuracy: 0.4187 - val_loss: 3.3418\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step - accuracy: 0.6125 - loss: 1.9378 - val_accuracy: 0.4187 - val_loss: 2.9692\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.6125 - loss: 1.9012 - val_accuracy: 0.4187 - val_loss: 3.2443\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.6125 - loss: 1.8952 - val_accuracy: 0.4187 - val_loss: 2.9622\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.6125 - loss: 1.8802 - val_accuracy: 0.4187 - val_loss: 3.2567\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.6133 - loss: 1.8832 - val_accuracy: 0.4187 - val_loss: 2.9220\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.6167 - loss: 1.8947 - val_accuracy: 0.4187 - val_loss: 3.3338\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.6125 - loss: 1.9166 - val_accuracy: 0.4187 - val_loss: 2.8585\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.6125 - loss: 1.9016 - val_accuracy: 0.4187 - val_loss: 3.3655\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.6125 - loss: 1.9233 - val_accuracy: 0.4187 - val_loss: 2.8806\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.6150 - loss: 1.8607 - val_accuracy: 0.4187 - val_loss: 3.1641\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.6125 - loss: 1.8435 - val_accuracy: 0.4344 - val_loss: 2.8658\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.6150 - loss: 1.8304 - val_accuracy: 0.4187 - val_loss: 3.2205\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.6150 - loss: 1.8501 - val_accuracy: 0.4406 - val_loss: 2.7844\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.6175 - loss: 1.8509 - val_accuracy: 0.4187 - val_loss: 3.2758\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.6125 - loss: 1.8581 - val_accuracy: 0.4187 - val_loss: 2.7638\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.6150 - loss: 1.8967 - val_accuracy: 0.4187 - val_loss: 3.5178\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.6133 - loss: 1.9588 - val_accuracy: 0.4469 - val_loss: 2.8309\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.6192 - loss: 1.8105 - val_accuracy: 0.4313 - val_loss: 3.0655\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.6150 - loss: 1.7890 - val_accuracy: 0.4250 - val_loss: 2.8002\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.6142 - loss: 1.8738 - val_accuracy: 0.4187 - val_loss: 3.0867\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.6167 - loss: 1.7951 - val_accuracy: 0.4281 - val_loss: 2.8483\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6175 - loss: 1.7846 - val_accuracy: 0.4250 - val_loss: 3.0828\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.6175 - loss: 1.7794 - val_accuracy: 0.4313 - val_loss: 2.7685\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.6167 - loss: 1.7774 - val_accuracy: 0.4313 - val_loss: 3.1924\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.6150 - loss: 1.7874 - val_accuracy: 0.4531 - val_loss: 2.7055\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.6233 - loss: 1.8087 - val_accuracy: 0.4313 - val_loss: 3.2082\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.6150 - loss: 1.7857 - val_accuracy: 0.4594 - val_loss: 2.7009\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6242 - loss: 1.7868 - val_accuracy: 0.4281 - val_loss: 3.1506\n",
            "ITU Admissions Chatbot: Hi! I can answer questions about ITU admissions. Type 'bye' to exit.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "import random\n",
        "\n",
        "# Data Collection - Using default data since web scraping might not be reliable\n",
        "itu_data = {\n",
        "    \"programs\": {\n",
        "        \"BS\": [\"Computer Science\", \"Electrical Engineering\", \"Business & Technology\",\n",
        "               \"Social Sciences\", \"Artificial Intelligence\"],\n",
        "        \"MS\": [\"Computer Science\", \"Electrical Engineering\", \"Data Science\",\n",
        "               \"Innovation & Entrepreneurship\"],\n",
        "        \"PhD\": [\"Computer Science\", \"Electrical Engineering\", \"Information Technology\"]\n",
        "    },\n",
        "    \"admissions\": {\n",
        "        \"deadlines\": \"Fall 2023: July 15, 2023 | Spring 2024: December 15, 2023\",\n",
        "        \"criteria\": \"BS: 60% in intermediate\\nMS: 2.5 CGPA in BS\\nPhD: 3.0 CGPA in MS\\nAdmission test and interview required\",\n",
        "        \"test_dates\": \"Fall: July 30, 2023 | Spring: January 5, 2024\"\n",
        "    },\n",
        "    \"fees\": \"BS: ~PKR 80,000/semester\\nMS: ~PKR 100,000/semester\\nPhD: ~PKR 120,000/semester\",\n",
        "    \"scholarships\": [\n",
        "        \"Merit scholarships (up to 100% tuition)\",\n",
        "        \"Need-based scholarships\",\n",
        "        \"HEC scholarships for eligible students\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create question-answer pairs\n",
        "pairs = [\n",
        "    # Programs\n",
        "    [\"How many BS programs does ITU offer?\",\n",
        "     f\"ITU currently offers {len(itu_data['programs']['BS'])} BS programs: {', '.join(itu_data['programs']['BS'])}.\"],\n",
        "    [\"How many MS programs does ITU offer?\",\n",
        "     f\"ITU offers {len(itu_data['programs']['MS'])} MS programs: {', '.join(itu_data['programs']['MS'])}.\"],\n",
        "    [\"How many PhD programs does ITU offer?\",\n",
        "     f\"ITU has {len(itu_data['programs']['PhD'])} PhD programs: {', '.join(itu_data['programs']['PhD'])}.\"],\n",
        "    [\"What programs does ITU offer?\",\n",
        "     f\"ITU offers programs at BS, MS and PhD levels. BS: {', '.join(itu_data['programs']['BS'])}. MS: {', '.join(itu_data['programs']['MS'])}. PhD: {', '.join(itu_data['programs']['PhD'])}.\"],\n",
        "\n",
        "    # Admissions\n",
        "    [\"What is the admission application deadline?\",\n",
        "     f\"Admission deadlines: {itu_data['admissions']['deadlines']}\"],\n",
        "    [\"What are the admission criteria?\",\n",
        "     f\"Admission criteria:\\n{itu_data['admissions']['criteria']}\"],\n",
        "    [\"Tell me about ITU admissions\",\n",
        "     f\"ITU admissions information:\\nDeadlines: {itu_data['admissions']['deadlines']}\\nCriteria:\\n{itu_data['admissions']['criteria']}\"],\n",
        "\n",
        "    # Fees\n",
        "    [\"What is the fee structure?\",\n",
        "     f\"Fee structure:\\n{itu_data['fees']}\"],\n",
        "    [\"How much does it cost to study at ITU?\",\n",
        "     f\"ITU fees:\\n{itu_data['fees']}\"],\n",
        "\n",
        "    # Scholarships\n",
        "    [\"What scholarships are available?\",\n",
        "     f\"Scholarships available at ITU:\\n- \" + \"\\n- \".join(itu_data['scholarships'])],\n",
        "    [\"Is there any financial aid?\",\n",
        "     f\"Yes, ITU offers several financial aid options:\\n- \" + \"\\n- \".join(itu_data['scholarships'])],\n",
        "\n",
        "    # General\n",
        "    [\"hello\", \"Hello! Welcome to ITU Admissions Chatbot. How can I help you?\"],\n",
        "    [\"hi\", \"Hi there! I'm the ITU Admissions Bot. What would you like to know?\"],\n",
        "    [\"bye\", \"Goodbye! If you have more questions about ITU admissions, feel free to ask later.\"]\n",
        "]\n",
        "\n",
        "# Add more variations\n",
        "questions = [\n",
        "    \"number of bs programs\", \"bs programs count\", \"undergraduate programs\",\n",
        "    \"ms programs number\", \"graduate programs count\", \"masters programs\",\n",
        "    \"phd programs count\", \"doctoral programs\", \"phd offerings\",\n",
        "    \"admission deadline\", \"last date to apply\", \"application due date\",\n",
        "    \"admission requirements\", \"eligibility criteria\", \"what do i need to apply\",\n",
        "    \"tuition fees\", \"fee details\", \"cost of study\",\n",
        "    \"financial aid\", \"scholarship options\", \"funding opportunities\",\n",
        "    \"what can i study at itu\", \"programs offered\", \"courses available\"\n",
        "]\n",
        "\n",
        "answers = [\n",
        "    pairs[0][1], pairs[0][1], pairs[0][1],\n",
        "    pairs[1][1], pairs[1][1], pairs[1][1],\n",
        "    pairs[2][1], pairs[2][1], pairs[2][1],\n",
        "    pairs[4][1], pairs[4][1], pairs[4][1],\n",
        "    pairs[5][1], pairs[5][1], pairs[5][1],\n",
        "    pairs[7][1], pairs[7][1], pairs[7][1],\n",
        "    pairs[9][1], pairs[9][1], pairs[9][1],\n",
        "    pairs[3][1], pairs[3][1], pairs[3][1]\n",
        "]\n",
        "\n",
        "# Combine the pairs\n",
        "for q, a in zip(questions, answers):\n",
        "    pairs.append([q, a])\n",
        "\n",
        "# Prepare data for the model\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_words = set()\n",
        "target_words = set()\n",
        "\n",
        "# Use special tokens\n",
        "start_token = \"<START>\"\n",
        "end_token = \"<END>\"\n",
        "\n",
        "for pair in pairs:\n",
        "    input_text = pair[0].lower()\n",
        "    target_text = pair[1].lower()\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(start_token + \" \" + target_text + \" \" + end_token)\n",
        "\n",
        "    # Collect vocabulary\n",
        "    for word in input_text.split():\n",
        "        if word not in input_words:\n",
        "            input_words.add(word)\n",
        "    for word in target_text.split():\n",
        "        if word not in target_words:\n",
        "            target_words.add(word)\n",
        "\n",
        "# Tokenization\n",
        "num_encoder_tokens = len(input_words) + 1  # +1 for padding\n",
        "num_decoder_tokens = len(target_words) + 2  # +2 for start and end tokens\n",
        "max_encoder_seq_length = max(len(txt.split()) for txt in input_texts)\n",
        "max_decoder_seq_length = max(len(txt.split()) for txt in target_texts)\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "# Create tokenizers\n",
        "tokenizer_inputs = Tokenizer(num_words=num_encoder_tokens, filters='')\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "encoder_input_data = pad_sequences(input_sequences, maxlen=max_encoder_seq_length, padding='post')\n",
        "\n",
        "tokenizer_outputs = Tokenizer(num_words=num_decoder_tokens, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts)\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences = [seq[1:] for seq in target_sequences]  # Remove start token\n",
        "decoder_input_data = pad_sequences(target_sequences, maxlen=max_decoder_seq_length, padding='post')\n",
        "\n",
        "target_sequences_next = [seq[1:] for seq in tokenizer_outputs.texts_to_sequences(target_texts)]\n",
        "decoder_target_data = pad_sequences(target_sequences_next, maxlen=max_decoder_seq_length, padding='post')\n",
        "\n",
        "# Convert to one-hot\n",
        "encoder_input_data = tf.keras.utils.to_categorical(encoder_input_data, num_encoder_tokens)\n",
        "decoder_input_data = tf.keras.utils.to_categorical(decoder_input_data, num_decoder_tokens)\n",
        "decoder_target_data = tf.keras.utils.to_categorical(decoder_target_data, num_decoder_tokens)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=32,\n",
        "          epochs=50,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Inference models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse lookup token index to decode sequences back to words\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in tokenizer_inputs.word_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in tokenizer_outputs.word_index.items())\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character\n",
        "    start_token_index = tokenizer_outputs.word_index.get(start_token.lower(), 0)\n",
        "    target_seq[0, 0, start_token_index] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index.get(sampled_token_index, '')\n",
        "        decoded_sentence += sampled_char + ' '\n",
        "\n",
        "        # Exit condition: either hit max length or find stop character\n",
        "        if (sampled_char == end_token.lower() or\n",
        "            len(decoded_sentence.split()) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    # Remove start and end tokens from the final output\n",
        "    decoded_sentence = decoded_sentence.replace(start_token.lower(), '').replace(end_token.lower(), '')\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "# Chatbot interface\n",
        "def chat():\n",
        "    print(\"ITU Admissions Chatbot: Hi! I can answer questions about ITU admissions. Type 'bye' to exit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == 'bye':\n",
        "            print(\"ITU Admissions Chatbot: Goodbye! Have a great day.\")\n",
        "            break\n",
        "\n",
        "        # Preprocess user input\n",
        "        input_seq = tokenizer_inputs.texts_to_sequences([user_input.lower()])\n",
        "        if not input_seq or not input_seq[0]:  # If no tokens found\n",
        "            print(\"ITU Admissions Chatbot: I'm not sure I understand. Could you rephrase your question?\")\n",
        "            continue\n",
        "\n",
        "        input_seq = pad_sequences(input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
        "        input_seq = tf.keras.utils.to_categorical(input_seq, num_encoder_tokens)\n",
        "\n",
        "        # Get response\n",
        "        decoded_sentence = decode_sequence(input_seq)\n",
        "        print(\"ITU Admissions Chatbot:\", decoded_sentence.capitalize())\n",
        "\n",
        "# Start chatting\n",
        "chat()"
      ]
    }
  ]
}